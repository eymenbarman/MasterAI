{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":96164,"databundleVersionId":11418275,"sourceType":"competition"},{"sourceId":242789450,"sourceType":"kernelVersion"}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"papermill":{"default_parameters":{},"duration":9319.126687,"end_time":"2025-05-28T09:27:09.13245","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-05-28T06:51:50.005763","version":"2.6.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install koolbox scikit-learn==1.5.2","metadata":{"_kg_hide-output":true,"papermill":{"duration":9.880461,"end_time":"2025-05-28T06:52:05.221127","exception":false,"start_time":"2025-05-28T06:51:55.340666","status":"completed"},"scrolled":true,"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"EBARMAN TRANSFER-RIVAL INSIGHT","metadata":{}},{"cell_type":"code","source":"!pip install scikit-learn==1.5.2 lightgbm xgboost catboost optuna\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T02:13:18.789606Z","iopub.execute_input":"2025-06-03T02:13:18.789949Z","iopub.status.idle":"2025-06-03T02:13:29.269052Z","shell.execute_reply.started":"2025-06-03T02:13:18.789925Z","shell.execute_reply":"2025-06-03T02:13:29.267892Z"}},"outputs":[{"name":"stdout","text":"Collecting scikit-learn==1.5.2\n  Downloading scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\nRequirement already satisfied: lightgbm in /usr/local/lib/python3.11/dist-packages (4.5.0)\nRequirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.0.3)\nRequirement already satisfied: catboost in /usr/local/lib/python3.11/dist-packages (1.2.8)\nRequirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.3.0)\nRequirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.5.2) (1.26.4)\nRequirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.5.2) (1.15.2)\nRequirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.5.2) (1.5.0)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.5.2) (3.6.0)\nRequirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.20.3)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.7.2)\nRequirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.3)\nRequirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\nRequirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\nRequirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.15.2)\nRequirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.9.0)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (25.0)\nRequirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.40)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\nRequirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\nRequirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\nRequirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.13.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.5->scikit-learn==1.5.2) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.5->scikit-learn==1.5.2) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.5->scikit-learn==1.5.2) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.5->scikit-learn==1.5.2) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.5->scikit-learn==1.5.2) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.5->scikit-learn==1.5.2) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\nRequirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.57.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.1.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.0.9)\nRequirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (9.1.2)\nRequirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.5->scikit-learn==1.5.2) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.5->scikit-learn==1.5.2) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.19.5->scikit-learn==1.5.2) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.19.5->scikit-learn==1.5.2) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.19.5->scikit-learn==1.5.2) (2024.2.0)\nDownloading scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0m\n\u001b[?25hInstalling collected packages: scikit-learn\n  Attempting uninstall: scikit-learn\n    Found existing installation: scikit-learn 1.2.2\n    Uninstalling scikit-learn-1.2.2:\n      Successfully uninstalled scikit-learn-1.2.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed scikit-learn-1.5.2\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nimport gc\nimport optuna\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.ensemble import RandomForestRegressor\nfrom lightgbm import LGBMRegressor\nfrom xgboost import XGBRegressor\nfrom catboost import CatBoostRegressor\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T02:13:37.254862Z","iopub.execute_input":"2025-06-03T02:13:37.255239Z","iopub.status.idle":"2025-06-03T02:13:44.719964Z","shell.execute_reply.started":"2025-06-03T02:13:37.255204Z","shell.execute_reply":"2025-06-03T02:13:44.718920Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"warnings.filterwarnings(\"ignore\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T02:13:51.648850Z","iopub.execute_input":"2025-06-03T02:13:51.649522Z","iopub.status.idle":"2025-06-03T02:13:51.654145Z","shell.execute_reply.started":"2025-06-03T02:13:51.649495Z","shell.execute_reply":"2025-06-03T02:13:51.653088Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"class CFG:\n    train_path = \"/kaggle/input/drw-crypto-market-prediction/train.parquet\"\n    test_path = \"/kaggle/input/drw-crypto-market-prediction/test.parquet\"\n    sample_submission_path = \"/kaggle/input/drw-crypto-market-prediction/sample_submission.csv\"\n\n    target = \"label\"\n    n_folds = 5\n    seed = 42","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T02:13:57.694830Z","iopub.execute_input":"2025-06-03T02:13:57.695175Z","iopub.status.idle":"2025-06-03T02:13:57.700618Z","shell.execute_reply.started":"2025-06-03T02:13:57.695151Z","shell.execute_reply":"2025-06-03T02:13:57.699267Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def reduce_mem_usage(df, name=\"\"):\n    print(f\"‚è¨ Bellek azaltƒ±lƒ±yor: {name}\")\n    start_mem = df.memory_usage().sum() / 1024**2\n\n    for col in df.columns:\n        col_type = df[col].dtype\n\n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print(f\"üìâ Bellek (√∂nce): {start_mem:.2f} MB\")\n    print(f\"üìâ Bellek (sonra): {end_mem:.2f} MB\")\n    print(f\"‚û°Ô∏è Kazan√ß: {100 * (start_mem - end_mem) / start_mem:.1f}%\")\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T02:14:05.536757Z","iopub.execute_input":"2025-06-03T02:14:05.537129Z","iopub.status.idle":"2025-06-03T02:14:05.546478Z","shell.execute_reply.started":"2025-06-03T02:14:05.537100Z","shell.execute_reply":"2025-06-03T02:14:05.545463Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"train = pd.read_parquet(CFG.train_path)\ntest = pd.read_parquet(CFG.test_path)\n\n# Hedef s√ºtun ve silinecek X### kolonlarƒ±\ntarget = CFG.target\ncols_to_drop = [col for col in train.columns if \"X\" in col]\n\n# Kolonlarƒ± √ßƒ±kar\ntrain = train.drop(columns=cols_to_drop)\ntest = test.drop(columns=cols_to_drop + [target])\n\n# Bellek azaltma\ntrain = reduce_mem_usage(train, \"train\")\ntest = reduce_mem_usage(test, \"test\")\n\n# X ve y ayƒ±r\nX = train.drop(columns=[target])\ny = train[target]\nX_test = test.copy()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T02:14:14.494712Z","iopub.execute_input":"2025-06-03T02:14:14.495112Z","iopub.status.idle":"2025-06-03T02:15:03.845106Z","shell.execute_reply.started":"2025-06-03T02:14:14.495065Z","shell.execute_reply":"2025-06-03T02:15:03.843831Z"}},"outputs":[{"name":"stdout","text":"‚è¨ Bellek azaltƒ±lƒ±yor: train\nüìâ Bellek (√∂nce): 28.09 MB\nüìâ Bellek (sonra): 10.03 MB\n‚û°Ô∏è Kazan√ß: 64.3%\n‚è¨ Bellek azaltƒ±lƒ±yor: test\nüìâ Bellek (√∂nce): 20.53 MB\nüìâ Bellek (sonra): 5.13 MB\n‚û°Ô∏è Kazan√ß: 75.0%\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"def create_features(df):\n    df[\"buy_sell_ratio\"] = df[\"buy_qty\"] / (df[\"sell_qty\"] + 1e-8)\n    df[\"bid_ask_ratio\"] = df[\"bid_qty\"] / (df[\"ask_qty\"] + 1e-8)\n    df[\"liquidity\"] = df[\"bid_qty\"] + df[\"ask_qty\"]\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T02:15:03.846715Z","iopub.execute_input":"2025-06-03T02:15:03.847034Z","iopub.status.idle":"2025-06-03T02:15:03.852261Z","shell.execute_reply.started":"2025-06-03T02:15:03.847009Z","shell.execute_reply":"2025-06-03T02:15:03.851404Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def create_features(df):\n    df[\"buy_sell_ratio\"] = df[\"buy_qty\"] / (df[\"sell_qty\"] + 1e-8)\n    df[\"bid_ask_ratio\"] = df[\"bid_qty\"] / (df[\"ask_qty\"] + 1e-8)\n    df[\"liquidity\"] = df[\"bid_qty\"] + df[\"ask_qty\"]\n    return df\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T02:15:03.853220Z","iopub.execute_input":"2025-06-03T02:15:03.853900Z","iopub.status.idle":"2025-06-03T02:15:03.888305Z","shell.execute_reply.started":"2025-06-03T02:15:03.853874Z","shell.execute_reply":"2025-06-03T02:15:03.887002Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"X = create_features(X)\nX_test = create_features(X_test)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T02:15:03.890252Z","iopub.execute_input":"2025-06-03T02:15:03.890621Z","iopub.status.idle":"2025-06-03T02:15:03.999927Z","shell.execute_reply.started":"2025-06-03T02:15:03.890585Z","shell.execute_reply":"2025-06-03T02:15:03.998959Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"from lightgbm import early_stopping\n\ndef train_and_evaluate(X, y, X_test, model_type=\"lgbm\"):\n    kf = KFold(n_splits=CFG.n_folds, shuffle=True, random_state=CFG.seed)\n\n    oof_preds = np.zeros(len(X))\n    test_preds = np.zeros(len(X_test))\n\n    for fold, (train_idx, val_idx) in enumerate(kf.split(X, y)):\n        print(f\"üìÇ Fold {fold + 1}\")\n\n        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n\n        if model_type == \"lgbm\":\n            model = LGBMRegressor(random_state=CFG.seed, n_estimators=1000)\n            model.fit(\n                X_train, y_train,\n                eval_set=[(X_val, y_val)],\n                callbacks=[early_stopping(stopping_rounds=50)],\n            )\n\n        elif model_type == \"xgb\":\n            model = XGBRegressor(random_state=CFG.seed, n_estimators=1000)\n            model.fit(\n                X_train, y_train,\n                eval_set=[(X_val, y_val)],\n                early_stopping_rounds=50,\n                verbose=100\n            )\n\n        elif model_type == \"catboost\":\n            model = CatBoostRegressor(random_state=CFG.seed, verbose=0)\n            model.fit(X_train, y_train, eval_set=(X_val, y_val))\n\n        elif model_type == \"rf\":\n            model = RandomForestRegressor(random_state=CFG.seed, n_estimators=200)\n            model.fit(X_train, y_train)\n\n        else:\n            raise ValueError(\"Model tipi tanƒ±nmadƒ±!\")\n\n        oof_preds[val_idx] = model.predict(X_val)\n        test_preds += model.predict(X_test) / CFG.n_folds\n\n        rmse = mean_squared_error(y_val, oof_preds[val_idx], squared=False)\n        print(f\"‚úÖ Fold {fold + 1} RMSE: {rmse:.4f}\")\n\n    final_rmse = mean_squared_error(y, oof_preds, squared=False)\n    print(f\"\\nüîö Final CV RMSE: {final_rmse:.4f}\")\n\n    return oof_preds, test_preds\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T02:16:43.730544Z","iopub.execute_input":"2025-06-03T02:16:43.731669Z","iopub.status.idle":"2025-06-03T02:16:43.747121Z","shell.execute_reply.started":"2025-06-03T02:16:43.731630Z","shell.execute_reply":"2025-06-03T02:16:43.745856Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"oof_preds, test_preds = train_and_evaluate(X, y, X_test, model_type=\"lgbm\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T02:16:52.032208Z","iopub.execute_input":"2025-06-03T02:16:52.032546Z","iopub.status.idle":"2025-06-03T02:16:59.429304Z","shell.execute_reply.started":"2025-06-03T02:16:52.032522Z","shell.execute_reply":"2025-06-03T02:16:59.428277Z"}},"outputs":[{"name":"stdout","text":"üìÇ Fold 1\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020248 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2040\n[LightGBM] [Info] Number of data points in the train set: 420709, number of used features: 8\n[LightGBM] [Info] Start training from score 0.037167\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[16]\tvalid_0's l2: 1.03179\n‚úÖ Fold 1 RMSE: 1.0158\nüìÇ Fold 2\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016936 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2040\n[LightGBM] [Info] Number of data points in the train set: 420709, number of used features: 8\n[LightGBM] [Info] Start training from score 0.035595\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[12]\tvalid_0's l2: 1.0274\n‚úÖ Fold 2 RMSE: 1.0136\nüìÇ Fold 3\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017664 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2040\n[LightGBM] [Info] Number of data points in the train set: 420710, number of used features: 8\n[LightGBM] [Info] Start training from score 0.036845\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[9]\tvalid_0's l2: 1.00421\n‚úÖ Fold 3 RMSE: 1.0021\nüìÇ Fold 4\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017523 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2040\n[LightGBM] [Info] Number of data points in the train set: 420710, number of used features: 8\n[LightGBM] [Info] Start training from score 0.035633\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[13]\tvalid_0's l2: 1.03306\n‚úÖ Fold 4 RMSE: 1.0164\nüìÇ Fold 5\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018484 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2040\n[LightGBM] [Info] Number of data points in the train set: 420710, number of used features: 8\n[LightGBM] [Info] Start training from score 0.035389\nTraining until validation scores don't improve for 50 rounds\nEarly stopping, best iteration is:\n[16]\tvalid_0's l2: 0.997074\n‚úÖ Fold 5 RMSE: 0.9985\n\nüîö Final CV RMSE: 1.0093\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"sample_submission = pd.read_csv(CFG.sample_submission_path)\nsample_submission[CFG.target] = test_preds\nsample_submission.to_csv(\"submission.csv\", index=False)\n\nprint(\"‚úÖ Submission dosyasƒ± kaydedildi.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T02:17:05.793063Z","iopub.execute_input":"2025-06-03T02:17:05.793850Z","iopub.status.idle":"2025-06-03T02:17:08.343012Z","shell.execute_reply.started":"2025-06-03T02:17:05.793795Z","shell.execute_reply":"2025-06-03T02:17:08.342189Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Submission dosyasƒ± kaydedildi.\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"def objective_lgbm(trial):\n    params = {\n        \"n_estimators\": 1000,\n        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.005, 0.3),\n        \"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 3000),\n        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 15),\n        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n        \"subsample\": trial.suggest_float(\"subsample\", 0.4, 1.0),\n        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.4, 1.0),\n        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0.0, 5.0),\n        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0.0, 5.0),\n        \"random_state\": CFG.seed\n    }\n\n    kf = KFold(n_splits=3, shuffle=True, random_state=CFG.seed)\n    scores = []\n\n    for train_idx, val_idx in kf.split(X, y):\n        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n\n        model = LGBMRegressor(**params)\n        model.fit(\n            X_train, y_train,\n            eval_set=[(X_val, y_val)],\n            callbacks=[early_stopping(50)],\n            verbose=0\n        )\n\n        preds = model.predict(X_val)\n        score = mean_squared_error(y_val, preds, squared=False)\n        scores.append(score)\n\n    return np.mean(scores)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T02:21:31.142767Z","iopub.execute_input":"2025-06-03T02:21:31.143102Z","iopub.status.idle":"2025-06-03T02:21:31.152792Z","shell.execute_reply.started":"2025-06-03T02:21:31.143065Z","shell.execute_reply":"2025-06-03T02:21:31.151709Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"from lightgbm import LGBMRegressor\nimport joblib\n\nmodel = LGBMRegressor(random_state=42)\nmodel.fit(X, y)\n\njoblib.dump(model, \"model_lgbm.h5\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T02:22:07.877933Z","iopub.execute_input":"2025-06-03T02:22:07.878287Z","iopub.status.idle":"2025-06-03T02:22:09.399829Z","shell.execute_reply.started":"2025-06-03T02:22:07.878261Z","shell.execute_reply":"2025-06-03T02:22:09.398947Z"}},"outputs":[{"name":"stdout","text":"[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023172 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 2040\n[LightGBM] [Info] Number of data points in the train set: 525887, number of used features: 8\n[LightGBM] [Info] Start training from score 0.036126\n","output_type":"stream"},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"['model_lgbm.h5']"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Imports and configs","metadata":{"papermill":{"duration":0.004954,"end_time":"2025-05-28T06:52:05.231905","exception":false,"start_time":"2025-05-28T06:52:05.226951","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.linear_model import Ridge\nfrom lightgbm import LGBMRegressor\nfrom scipy.stats import pearsonr as pr\nfrom xgboost import XGBRegressor\nfrom sklearn.base import clone\nfrom koolbox import Trainer\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nimport warnings\nimport optuna\nimport joblib\nimport glob\nimport gc\n\nwarnings.filterwarnings(\"ignore\")","metadata":{"_kg_hide-output":true,"papermill":{"duration":9.349738,"end_time":"2025-05-28T06:52:14.586711","exception":false,"start_time":"2025-05-28T06:52:05.236973","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class CFG:\n    train_path = \"/kaggle/input/drw-crypto-market-prediction/train.parquet\"\n    test_path = \"/kaggle/input/drw-crypto-market-prediction/test.parquet\"\n    sample_sub_path = \"/kaggle/input/drw-crypto-market-prediction/sample_submission.csv\"\n\n    target = \"label\"\n    n_folds = 5\n    seed = 42\n\n    run_optuna = True\n    n_optuna_trials = 500","metadata":{"papermill":{"duration":0.012421,"end_time":"2025-05-28T06:52:14.604593","exception":false,"start_time":"2025-05-28T06:52:14.592172","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data loading and preprocessing","metadata":{"papermill":{"duration":0.004888,"end_time":"2025-05-28T06:52:14.614896","exception":false,"start_time":"2025-05-28T06:52:14.610008","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def reduce_mem_usage(dataframe, dataset):    \n    print('Reducing memory usage for:', dataset)\n    initial_mem_usage = dataframe.memory_usage().sum() / 1024**2\n    \n    for col in dataframe.columns:\n        col_type = dataframe[col].dtype\n\n        c_min = dataframe[col].min()\n        c_max = dataframe[col].max()\n        if str(col_type)[:3] == 'int':\n            if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                dataframe[col] = dataframe[col].astype(np.int8)\n            elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                dataframe[col] = dataframe[col].astype(np.int16)\n            elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                dataframe[col] = dataframe[col].astype(np.int32)\n            elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                dataframe[col] = dataframe[col].astype(np.int64)\n        else:\n            if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                dataframe[col] = dataframe[col].astype(np.float16)\n            elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                dataframe[col] = dataframe[col].astype(np.float32)\n            else:\n                dataframe[col] = dataframe[col].astype(np.float64)\n\n    final_mem_usage = dataframe.memory_usage().sum() / 1024**2\n    print('--- Memory usage before: {:.2f} MB'.format(initial_mem_usage))\n    print('--- Memory usage after: {:.2f} MB'.format(final_mem_usage))\n    print('--- Decreased memory usage by {:.1f}%\\n'.format(100 * (initial_mem_usage - final_mem_usage) / initial_mem_usage))\n\n    return dataframe","metadata":{"_kg_hide-input":true,"papermill":{"duration":0.016341,"end_time":"2025-05-28T06:52:14.636335","exception":false,"start_time":"2025-05-28T06:52:14.619994","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def add_features(df):\n    data = df.copy()\n    features_df = pd.DataFrame(index=data.index)\n    \n    features_df['bid_ask_spread_proxy'] = data['ask_qty'] - data['bid_qty']\n    features_df['total_liquidity'] = data['bid_qty'] + data['ask_qty']\n    features_df['trade_imbalance'] = data['buy_qty'] - data['sell_qty']\n    features_df['total_trades'] = data['buy_qty'] + data['sell_qty']\n    \n    features_df['volume_per_trade'] = data['volume'] / (data['buy_qty'] + data['sell_qty'] + 1e-8)\n    features_df['buy_volume_ratio'] = data['buy_qty'] / (data['volume'] + 1e-8)\n    features_df['sell_volume_ratio'] = data['sell_qty'] / (data['volume'] + 1e-8)\n    \n    features_df['buying_pressure'] = data['buy_qty'] / (data['buy_qty'] + data['sell_qty'] + 1e-8)\n    features_df['selling_pressure'] = data['sell_qty'] / (data['buy_qty'] + data['sell_qty'] + 1e-8)\n    \n    features_df['order_imbalance'] = (data['bid_qty'] - data['ask_qty']) / (data['bid_qty'] + data['ask_qty'] + 1e-8)\n    features_df['order_imbalance_abs'] = np.abs(features_df['order_imbalance'])\n    features_df['bid_liquidity_ratio'] = data['bid_qty'] / (data['volume'] + 1e-8)\n    features_df['ask_liquidity_ratio'] = data['ask_qty'] / (data['volume'] + 1e-8)\n    features_df['market_depth'] = data['bid_qty'] + data['ask_qty']\n    features_df['depth_imbalance'] = features_df['market_depth'] - data['volume']\n    \n    features_df['buy_sell_ratio'] = data['buy_qty'] / (data['sell_qty'] + 1e-8)\n    features_df['bid_ask_ratio'] = data['bid_qty'] / (data['ask_qty'] + 1e-8)\n    features_df['volume_liquidity_ratio'] = data['volume'] / (data['bid_qty'] + data['ask_qty'] + 1e-8)\n\n    features_df['buy_volume_product'] = data['buy_qty'] * data['volume']\n    features_df['sell_volume_product'] = data['sell_qty'] * data['volume']\n    features_df['bid_ask_product'] = data['bid_qty'] * data['ask_qty']\n    \n    features_df['market_competition'] = (data['buy_qty'] * data['sell_qty']) / ((data['buy_qty'] + data['sell_qty']) + 1e-8)\n    features_df['liquidity_competition'] = (data['bid_qty'] * data['ask_qty']) / ((data['bid_qty'] + data['ask_qty']) + 1e-8)\n    \n    total_activity = data['buy_qty'] + data['sell_qty'] + data['bid_qty'] + data['ask_qty']\n    features_df['market_activity'] = total_activity\n    features_df['activity_concentration'] = data['volume'] / (total_activity + 1e-8)\n    \n    features_df['info_arrival_rate'] = (data['buy_qty'] + data['sell_qty']) / (data['volume'] + 1e-8)\n    features_df['market_making_intensity'] = (data['bid_qty'] + data['ask_qty']) / (data['buy_qty'] + data['sell_qty'] + 1e-8)\n    features_df['effective_spread_proxy'] = np.abs(data['buy_qty'] - data['sell_qty']) / (data['volume'] + 1e-8)\n    \n    lambda_decay = 0.95\n    ofi = data['buy_qty'] - data['sell_qty']\n    features_df['order_flow_imbalance_ewm'] = ofi.ewm(alpha=1-lambda_decay).mean()\n\n    features_df = features_df.replace([np.inf, -np.inf], np.nan)\n    \n    return features_df","metadata":{"papermill":{"duration":0.018954,"end_time":"2025-05-28T06:52:14.660863","exception":false,"start_time":"2025-05-28T06:52:14.641909","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cols_to_drop = [\n    'X697', 'X698', 'X699', 'X700', 'X701', 'X702', 'X703', 'X704', 'X705', 'X706', \n    'X707', 'X708', 'X709', 'X710', 'X711', 'X712', 'X713', 'X714', 'X715', 'X716',\n    'X717', 'X864', 'X867', 'X869', 'X870', 'X871', 'X872', 'X104', 'X110', 'X116',\n    'X122', 'X128', 'X134', 'X140', 'X146', 'X152', 'X158', 'X164', 'X170', 'X176',\n    'X182', 'X351', 'X357', 'X363', 'X369', 'X375', 'X381', 'X387', 'X393', 'X399',\n    'X405', 'X411', 'X417', 'X423', 'X429'\n]","metadata":{"papermill":{"duration":0.012943,"end_time":"2025-05-28T06:52:14.679287","exception":false,"start_time":"2025-05-28T06:52:14.666344","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train = pd.read_parquet(CFG.train_path).reset_index(drop=True)\ntest = pd.read_parquet(CFG.test_path).reset_index(drop=True)\n\ntrain = train.drop(columns=cols_to_drop)\ntest = test.drop(columns=[\"label\"] + cols_to_drop)\n\ntrain = reduce_mem_usage(train, \"train\")\ntest = reduce_mem_usage(test, \"test\")\n\nX = train.drop(CFG.target, axis=1)\ny = train[CFG.target]\nX_test = test","metadata":{"papermill":{"duration":70.181095,"end_time":"2025-05-28T06:53:24.866518","exception":false,"start_time":"2025-05-28T06:52:14.685423","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X = pd.concat([add_features(X), X], axis=1)\nX_test = pd.concat([add_features(X_test), X_test], axis=1)","metadata":{"papermill":{"duration":6.222914,"end_time":"2025-05-28T06:53:31.09571","exception":false,"start_time":"2025-05-28T06:53:24.872796","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training base models","metadata":{"papermill":{"duration":0.005181,"end_time":"2025-05-28T06:53:31.106911","exception":false,"start_time":"2025-05-28T06:53:31.10173","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def pearsonr(y_true, y_pred):\n    return pr(y_true, y_pred)[0]","metadata":{"papermill":{"duration":0.012196,"end_time":"2025-05-28T06:53:31.124498","exception":false,"start_time":"2025-05-28T06:53:31.112302","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lgbm_params = {\n    \"boosting_type\": \"gbdt\",\n    \"colsample_bytree\": 0.5625888953382505,\n    \"learning_rate\": 0.029312951475451557,\n    \"min_child_samples\": 63,\n    \"min_child_weight\": 0.11456572852335424,\n    \"n_estimators\": 126,\n    \"n_jobs\": -1,\n    \"num_leaves\": 37,\n    \"random_state\": 42,\n    \"reg_alpha\": 85.2476527854083,\n    \"reg_lambda\": 99.38305361388907,\n    \"subsample\": 0.450669817684892,\n    \"verbose\": -1\n}\n\nlgbm_goss_params = {\n    \"boosting_type\": \"goss\",\n    \"colsample_bytree\": 0.34695458228489784,\n    \"learning_rate\": 0.031023014900595287,\n    \"min_child_samples\": 30,\n    \"min_child_weight\": 0.4727729225033618,\n    \"n_estimators\": 220,\n    \"n_jobs\": -1,\n    \"num_leaves\": 58,\n    \"random_state\": 42,\n    \"reg_alpha\": 38.665994901468224,\n    \"reg_lambda\": 92.76991677464294,\n    \"subsample\": 0.4810891284493255,\n    \"verbose\": -1\n}\n\nxgb_params = {\n    \"colsample_bylevel\": 0.4778015829774066,\n    \"colsample_bynode\": 0.362764358742407,\n    \"colsample_bytree\": 0.7107423488010493,\n    \"gamma\": 1.7094857725240398,\n    \"learning_rate\": 0.02213323588455387,\n    \"max_depth\": 20,\n    \"max_leaves\": 12,\n    \"min_child_weight\": 16,\n    \"n_estimators\": 1667,\n    \"n_jobs\": -1,\n    \"random_state\": 42,\n    \"reg_alpha\": 39.352415706891264,\n    \"reg_lambda\": 75.44843704068275,\n    \"subsample\": 0.06566669853471274,\n    \"verbosity\": 0\n}","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"papermill":{"duration":0.016101,"end_time":"2025-05-28T06:53:31.146099","exception":false,"start_time":"2025-05-28T06:53:31.129998","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fold_scores = {}\noverall_scores = {}\n\noof_preds = {}\ntest_preds = {}","metadata":{"papermill":{"duration":0.011971,"end_time":"2025-05-28T06:53:31.163714","exception":false,"start_time":"2025-05-28T06:53:31.151743","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## LightGBM (gbdt)","metadata":{"papermill":{"duration":0.005429,"end_time":"2025-05-28T06:53:31.175035","exception":false,"start_time":"2025-05-28T06:53:31.169606","status":"completed"},"tags":[]}},{"cell_type":"code","source":"lgbm_trainer = Trainer(\n    LGBMRegressor(**lgbm_params),\n    cv=KFold(n_splits=5, shuffle=False),\n    metric=pearsonr,\n    task=\"regression\",\n    metric_precision=6\n)\n\nlgbm_trainer.fit(X, y)\n\nfold_scores[\"LightGBM (gbdt)\"] = lgbm_trainer.fold_scores\noverall_scores[\"LightGBM (gbdt)\"] = [pearsonr(lgbm_trainer.oof_preds, y)]\noof_preds[\"LightGBM (gbdt)\"] = lgbm_trainer.oof_preds\ntest_preds[\"LightGBM (gbdt)\"] = lgbm_trainer.predict(X_test)","metadata":{"papermill":{"duration":546.840654,"end_time":"2025-05-28T07:02:38.021118","exception":false,"start_time":"2025-05-28T06:53:31.180464","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## LightGBM (goss)","metadata":{"papermill":{"duration":0.005909,"end_time":"2025-05-28T07:02:38.03509","exception":false,"start_time":"2025-05-28T07:02:38.029181","status":"completed"},"tags":[]}},{"cell_type":"code","source":"lgbm_goss_trainer = Trainer(\n    LGBMRegressor(**lgbm_goss_params),\n    cv=KFold(n_splits=5, shuffle=False),\n    metric=pearsonr,\n    task=\"regression\",\n    metric_precision=6\n)\n\nlgbm_goss_trainer.fit(X, y)\n\nfold_scores[\"LightGBM (goss)\"] = lgbm_goss_trainer.fold_scores\noverall_scores[\"LightGBM (goss)\"] = [pearsonr(lgbm_goss_trainer.oof_preds, y)]\noof_preds[\"LightGBM (goss)\"] = lgbm_goss_trainer.oof_preds\ntest_preds[\"LightGBM (goss)\"] = lgbm_goss_trainer.predict(X_test)","metadata":{"papermill":{"duration":601.870551,"end_time":"2025-05-28T07:12:39.911607","exception":false,"start_time":"2025-05-28T07:02:38.041056","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## XGBoost","metadata":{"papermill":{"duration":0.006095,"end_time":"2025-05-28T07:12:39.92472","exception":false,"start_time":"2025-05-28T07:12:39.918625","status":"completed"},"tags":[]}},{"cell_type":"code","source":"xgb_trainer = Trainer(\n    XGBRegressor(**xgb_params),\n    cv=KFold(n_splits=5, shuffle=False),\n    metric=pearsonr,\n    task=\"regression\",\n    metric_precision=6\n)\n\nxgb_trainer.fit(X, y)\n\nfold_scores[\"XGBoost\"] = xgb_trainer.fold_scores\noverall_scores[\"XGBoost\"] = [pearsonr(xgb_trainer.oof_preds, y)]\noof_preds[\"XGBoost\"] = xgb_trainer.oof_preds\ntest_preds[\"XGBoost\"] = xgb_trainer.predict(X_test)","metadata":{"papermill":{"duration":7831.931128,"end_time":"2025-05-28T09:23:11.86215","exception":false,"start_time":"2025-05-28T07:12:39.931022","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## AutoGluon","metadata":{}},{"cell_type":"code","source":"oof_preds_files = glob.glob(f'/kaggle/input/drw-crypto-market-prediction-autogluon/*_oof_preds_*.pkl')\ntest_preds_files = glob.glob(f'/kaggle/input/drw-crypto-market-prediction-autogluon/*_test_preds_*.pkl')\n\nag_oof_preds = joblib.load(oof_preds_files[0])\nag_test_preds = joblib.load(test_preds_files[0])\n\nag_score = [pearsonr(ag_oof_preds, y)]\n\nag_scores = []\nsplit = KFold(n_splits=CFG.n_folds).split(X, y)\nfor _, val_idx in split:\n    y_val = y[val_idx]\n    y_preds = ag_oof_preds[val_idx]   \n    score = pearsonr(y_preds, y_val)\n    ag_scores.append(score)\n    \noof_preds[\"AutoGluon\"], test_preds[\"AutoGluon\"], overall_scores[\"AutoGluon\"], fold_scores[\"AutoGluon\"] = ag_oof_preds, ag_test_preds, ag_score, ag_scores","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Ensembling with Ridge","metadata":{"papermill":{"duration":0.006948,"end_time":"2025-05-28T09:23:11.87793","exception":false,"start_time":"2025-05-28T09:23:11.870982","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def plot_weights(weights, title):\n    sorted_indices = np.argsort(weights[0])[::-1]\n    sorted_coeffs = np.array(weights[0])[sorted_indices]\n    sorted_model_names = np.array(list(oof_preds.keys()))[sorted_indices]\n\n    plt.figure(figsize=(10, weights.shape[1] * 0.5))\n    ax = sns.barplot(x=sorted_coeffs, y=sorted_model_names, palette=\"RdYlGn_r\")\n\n    for i, (value, name) in enumerate(zip(sorted_coeffs, sorted_model_names)):\n        if value >= 0:\n            ax.text(value, i, f\"{value:.3f}\", va=\"center\", ha=\"left\", color=\"black\")\n        else:\n            ax.text(value, i, f\"{value:.3f}\", va=\"center\", ha=\"right\", color=\"black\")\n\n    xlim = ax.get_xlim()\n    ax.set_xlim(xlim[0] - 0.1 * abs(xlim[0]), xlim[1] + 0.1 * abs(xlim[1]))\n\n    plt.title(title)\n    plt.xlabel(\"\")\n    plt.ylabel(\"\")\n    plt.tight_layout()\n    plt.show()","metadata":{"_kg_hide-input":true,"papermill":{"duration":0.019582,"end_time":"2025-05-28T09:23:11.904119","exception":false,"start_time":"2025-05-28T09:23:11.884537","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X = pd.DataFrame(oof_preds)\nX_test = pd.DataFrame(test_preds)","metadata":{"papermill":{"duration":0.115877,"end_time":"2025-05-28T09:23:12.026966","exception":false,"start_time":"2025-05-28T09:23:11.911089","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"joblib.dump(X, \"oof_preds.pkl\")\njoblib.dump(X_test, \"test_preds.pkl\")","metadata":{"papermill":{"duration":0.13148,"end_time":"2025-05-28T09:23:12.165729","exception":false,"start_time":"2025-05-28T09:23:12.034249","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def objective(trial):    \n    params = {\n        \"random_state\": CFG.seed,\n        \"alpha\": trial.suggest_float(\"alpha\", 0, 100),\n        \"tol\": trial.suggest_float(\"tol\", 1e-6, 1e-2),\n        \"fit_intercept\": trial.suggest_categorical(\"fit_intercept\", [True, False]),\n        \"positive\": trial.suggest_categorical(\"positive\", [True, False])\n    }\n\n    trainer = Trainer(\n        Ridge(**params),\n        cv=KFold(n_splits=5, shuffle=False),\n        metric=pearsonr,\n        task=\"regression\",\n        verbose=False\n    )\n    trainer.fit(X, y)\n    \n    return pearsonr(trainer.oof_preds, y)\n\nif CFG.run_optuna:\n    sampler = optuna.samplers.TPESampler(seed=CFG.seed, multivariate=True, n_startup_trials=CFG.n_optuna_trials // 10)\n    study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n    study.optimize(objective, n_trials=CFG.n_optuna_trials, n_jobs=-1, catch=(ValueError,))\n    best_params = study.best_params\n\n    ridge_params = {\n        \"random_state\": CFG.seed,\n        \"alpha\": best_params[\"alpha\"],\n        \"tol\": best_params[\"tol\"],\n        \"fit_intercept\": best_params[\"fit_intercept\"],\n        \"positive\": best_params[\"positive\"]\n    }\nelse:\n    ridge_params = {\n        \"random_state\": CFG.seed\n    }","metadata":{"_kg_hide-output":true,"papermill":{"duration":229.358176,"end_time":"2025-05-28T09:27:01.53106","exception":false,"start_time":"2025-05-28T09:23:12.172884","status":"completed"},"scrolled":true,"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ridge_trainer = Trainer(\n    Ridge(**ridge_params),\n    cv=KFold(n_splits=5, shuffle=False),\n    metric=pearsonr,\n    task=\"regression\",\n    metric_precision=6\n)\n\nridge_trainer.fit(X, y)\n\nfold_scores[\"Ridge (ensemble)\"] = ridge_trainer.fold_scores\noverall_scores[\"Ridge (ensemble)\"] = [pearsonr(ridge_trainer.oof_preds, y)]\nridge_test_preds = ridge_trainer.predict(X_test)","metadata":{"papermill":{"duration":1.116192,"end_time":"2025-05-28T09:27:02.667165","exception":false,"start_time":"2025-05-28T09:27:01.550973","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ridge_coeffs = np.zeros((1, X.shape[1]))\nfor m in ridge_trainer.estimators:\n    ridge_coeffs += m.coef_\nridge_coeffs = ridge_coeffs / len(ridge_trainer.estimators)\n\nplot_weights(ridge_coeffs, \"Ridge Coefficients\")","metadata":{"papermill":{"duration":0.381603,"end_time":"2025-05-28T09:27:03.067767","exception":false,"start_time":"2025-05-28T09:27:02.686164","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Submission","metadata":{"papermill":{"duration":0.019284,"end_time":"2025-05-28T09:27:03.107042","exception":false,"start_time":"2025-05-28T09:27:03.087758","status":"completed"},"tags":[]}},{"cell_type":"code","source":"sub = pd.read_csv(CFG.sample_sub_path)\nsub[\"prediction\"] = ridge_test_preds\nsub.to_csv(f\"sub_ridge_{overall_scores['Ridge (ensemble)'][0]:.6f}.csv\", index=False)\nsub.head()","metadata":{"papermill":{"duration":1.91128,"end_time":"2025-05-28T09:27:05.038651","exception":false,"start_time":"2025-05-28T09:27:03.127371","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Results","metadata":{"papermill":{"duration":0.020011,"end_time":"2025-05-28T09:27:05.079631","exception":false,"start_time":"2025-05-28T09:27:05.05962","status":"completed"},"tags":[]}},{"cell_type":"code","source":"fold_scores = pd.DataFrame(fold_scores)\noverall_scores = pd.DataFrame(overall_scores).transpose().sort_values(by=0, ascending=False)\norder = overall_scores.index.tolist()\n\nmin_score = overall_scores.values.flatten().min()\nmax_score = overall_scores.values.flatten().max()\npadding = (max_score - min_score) * 0.5\nlower_limit = min_score - padding\nupper_limit = max_score + padding\n\nfig, axs = plt.subplots(1, 2, figsize=(15, fold_scores.shape[1] * 0.5))\n\nboxplot = sns.boxplot(data=fold_scores, order=order, ax=axs[0], orient=\"h\", color=\"grey\")\naxs[0].set_title(f\"Fold Score\")\naxs[0].set_xlabel(\"\")\naxs[0].set_ylabel(\"\")\n\nbarplot = sns.barplot(x=overall_scores.values.flatten(), y=overall_scores.index, ax=axs[1], color=\"grey\")\naxs[1].set_title(f\"Overall Score\")\naxs[1].set_xlabel(\"\")\naxs[1].set_xlim(left=lower_limit, right=upper_limit)\naxs[1].set_ylabel(\"\")\n\nfor i, (score, model) in enumerate(zip(overall_scores.values.flatten(), overall_scores.index)):\n    color = \"cyan\" if \"ensemble\" in model.lower() else \"grey\"\n    barplot.patches[i].set_facecolor(color)\n    boxplot.patches[i].set_facecolor(color)\n    barplot.text(score, i, round(score, 6), va=\"center\")\n\nplt.tight_layout()\nplt.show()","metadata":{"papermill":{"duration":0.356656,"end_time":"2025-05-28T09:27:05.456995","exception":false,"start_time":"2025-05-28T09:27:05.100339","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null}]}